# 2025_AWS-DeepRacer_NTUT_第8組

> Reinforcement learning strategies for AWS DeepRacer — from stable baseline to sub-9 second laps on the re:Invent 2018 track.

本倉庫記錄了使用 **強化學習（Reinforcement Learning）** 技術，在 AWS DeepRacer 模擬器中針對 re:Invent 2018 賽道所進行的多階段訓練過程，最終成功達成 **單圈低於 9 秒** 的高速完賽模型。

---



## 🧪 訓練版本一覽

| 版本       | 動作空間變化                                  | reward 函數邏輯                          | 超參數調整                         | 圈速最佳    | 說明重點                                      |
| -------- | --------------------------------------- | ------------------------------------ | ----------------------------- | ------- | ----------------------------------------- |
| **v1.0** | 基礎 10 組：±30° / ±15° / 0° 對應 1.0–4.0 m/s | 極簡中心線判斷，只要沒出界就給 1.0                  | 預設參數（learning rate 0.0003、entropy 0.01）  | 11.062s | ✅ **穩定完賽的 baseline 模型**，適合作為 fine-tune 起點 |
| **v1.1** | ±30° 與 ±15° 各增 0.5 m/s                  | 增加速度獎勵與出界懲罰，強調速度與穩定性                 | 預設參數不變     | 9.011s  | 🔧 初步進行速度優化與懲罰設計，模型可穩定加速，圈速明顯進步           |
| **v1.2** | ±15°  2.5 m/s 增加到 3.0 m/s ，測試極限速度           | 引入多層 steering-speed 聯動懲罰             | learning rate 與 entropy 分別調降至 **0.00005**  和  **0.001**    | 8.817s  | 🧠 精細化轉向 + 速度配對，降低亂動作機率，進一步提升彎道效率與穩定性     |
| **v1.3** | ±15°  2.0 m/s 增加到 2.5 m/s ，進一步提升最小速度    | steering 分級處理（<5°, <15°, >15°）與調整懲罰比 | 繼續使用調整後的參數 | 8.617s  | 🪄 對轉向獎懲進行精調，讓模型在彎道決策更穩定，學習速度更快           |




📄 詳細內容請見：`v1.0/README.md`、`v1.1/README.md` 等
